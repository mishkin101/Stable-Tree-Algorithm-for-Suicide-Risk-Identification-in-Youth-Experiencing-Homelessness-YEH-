{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2563649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = Path(\"../src/dt-distance\").resolve()\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from dt_distance.data_processor import DataProcessor  # correct!\n",
    "from dt_distance.tree_parser import TreeParser\n",
    "from dt_distance.distance_calculator import DistanceCalculator\n",
    "from dt_distance.problem_params import ProblemParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params from paper\n",
    "depths = list(range(3, 13))\n",
    "min_samples = [3, 5, 10, 30, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a92e8d",
   "metadata": {},
   "source": [
    "## Step 1: Split Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcbf26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split data into two batches\n",
    "'''\n",
    "randonly split training data\n",
    "'''\n",
    "def random_train_split(X,y):\n",
    "    N = X.shape[0]\n",
    "    indices = np.random.permutation(N)\n",
    "    X0, y0 = X[indices[:N // 2]], y[indices[:N // 2]]\n",
    "    return X0, y0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceef0ec",
   "metadata": {},
   "source": [
    "## Step 2: Training the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper function to generate trained tree with sklearn DecisionTreeClassifier\n",
    "'''\n",
    "def train_decision_tree(X, y, depth, min_samples_leaf):\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, min_samples_leaf=min_samples_leaf)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e7c2c5",
   "metadata": {},
   "source": [
    "## Step 3: Bootstrap and Train $T_{0}$ Tree Set\n",
    "- subset $N_0$ of $N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Takes in X_0\n",
    "Take in full training data\n",
    "Sample with replacement\n",
    "'''\n",
    "def bootstrap_trees(X, y, depths, min_samples, B):\n",
    "    trees = []\n",
    "    for _ in range(B):\n",
    "        X_sample, y_sample = resample(X, y, replace= True)\n",
    "        depth = np.random.choice(depths)\n",
    "        min_leaf = np.random.choice(min_samples)\n",
    "        tree = train_decision_tree(X_sample, y_sample, depth, min_leaf)\n",
    "        trees.append(tree)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2436d",
   "metadata": {},
   "source": [
    "## Step 4: Train Second Tree Collection: $\\mathcal{T}$ (Call Bootstrap trees on X)\n",
    "- full training data $N$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375691cb",
   "metadata": {},
   "source": [
    "## Step 5: Compute Mean distance for each $T \\in T$\n",
    "- For each tree in $\\mathcal{T}$, compute `dt-distance` for all $T \\in T_{0}$ and average over all B\n",
    "- Compute AUC score from Test Data to get out-of-sample predictive power\n",
    "- Return $B$ average distances \n",
    "- Intuition for larger set: Say we get new data in the future-> how much do these new trees (entire set)$\\mathcal{T}$ deviate from the previosuly smaller set of trees $T_{0}$?\n",
    "- only structural differences (via path definitions) matter for problem params, so the path_converstion does not care about the dataset, but the bounds on features, quantification of categories, and assigned class labels as a sequence of splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_centroid_trees(trees_ref, trees_target, X,y):\n",
    "    distances = []\n",
    "    #TT\n",
    "    for target_tree in trees_target:\n",
    "            #t0\n",
    "            for ref_tree in trees_ref:\n",
    "                distance_calculator = DistanceCalculator(trees_target, ref_tree, X=X, y=y)\n",
    "                tree_dist = distance_calculator.compute_tree_distance()\n",
    "\n",
    "\n",
    "        parser_target = TreeParser(target_tree, problem_params)\n",
    "        paths_target = parser_target.get_paths()\n",
    "        distance_accum = 0\n",
    "\n",
    "            parser_ref = TreeParser(ref_tree, problem_params)\n",
    "            paths_ref = parser_ref.get_paths()\n",
    "            distance_accum += dt-distance(paths_ref, paths_target).calculate()\n",
    "        avg_distance = distance_accum / len(trees_ref)\n",
    "        distances.append(avg_distance)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def compute_tree_stability(trees_ref, trees_target, problem_params):\n",
    "    distances = []\n",
    "    for target_tree in trees_target:\n",
    "        parser_target = TreeParser(target_tree, problem_params)\n",
    "        paths_target = parser_target.get_paths()\n",
    "        distance_accum = 0\n",
    "        for ref_tree in trees_ref:\n",
    "            parser_ref = TreeParser(ref_tree, problem_params)\n",
    "            paths_ref = parser_ref.get_paths()\n",
    "            distance_accum += dt-distance(paths_ref, paths_target).calculate()\n",
    "        avg_distance = distance_accum / len(trees_ref)\n",
    "        distances.append(avg_distance)\n",
    "    return distances\n",
    "\n",
    "\n",
    "def evaluate_predictive_power(trees, X_holdout, y_holdout):\n",
    "    auc_scores = []\n",
    "    for tree in trees:\n",
    "        y_proba = tree.predict_proba(X_holdout)[:, 1]\n",
    "        auc = roc_auc_score(y_holdout, y_proba)\n",
    "        auc_scores.append(auc)\n",
    "    return auc_scores\n",
    "\n",
    "\n",
    "def pareto_optimal_trees(distances, auc_scores):\n",
    "    pareto_trees = []\n",
    "    for i, (d_i, a_i) in enumerate(zip(distances, auc_scores)):\n",
    "        dominated = False\n",
    "        for j, (d_j, a_j) in enumerate(zip(distances, auc_scores)):\n",
    "            if i != j and ((d_j <= d_i and a_j > a_i) or (d_j < d_i and a_j >= a_i)):\n",
    "                dominated = True\n",
    "                break\n",
    "        if not dominated:\n",
    "            pareto_trees.append(i)\n",
    "    return pareto_trees\n",
    "\n",
    "\n",
    "def select_final_tree(distances, auc_scores, pareto_indices, epsilon=0.01):\n",
    "    best_auc = max(auc_scores)\n",
    "    candidates = [i for i in pareto_indices if auc_scores[i] >= (1 - epsilon) * best_auc]\n",
    "    if not candidates:\n",
    "        candidates = pareto_indices\n",
    "    best_idx = max(candidates, key=lambda i: auc_scores[i] - distances[i])\n",
    "    return best_idx\n",
    "\n",
    "\n",
    "\n",
    "# Main method implementing the training of stable trees\n",
    "def train_stable_tree(X, y, X_holdout, y_holdout, B=20):\n",
    "    # Parameters\n",
    "    depths = list(range(3, 13))\n",
    "    min_samples = [3, 5, 10, 30, 50]\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize DataProcessor\n",
    "    dp = DataProcessor(data=X, target=y)\n",
    "    problem_params = dp.get_problem_params()\n",
    "\n",
    "    # Step 2: Train initial collection of trees\n",
    "    trees_batch_0 = bootstrap_trees(X0, y0, depths, min_samples, B)\n",
    "\n",
    "    # Step 3: Train second collection of trees on entire data\n",
    "    trees_full_batch = bootstrap_trees(X, y, depths, min_samples, B)\n",
    "\n",
    "    # Step 4: Compute stability and predictive performance\n",
    "    distances = compute_tree_stability(trees_batch_0, trees_full_batch, problem_params)\n",
    "    auc_scores = evaluate_predictive_power(trees_full_batch, X_holdout, y_holdout)\n",
    "\n",
    "    # Step 5: Pareto frontier\n",
    "    pareto_indices = pareto_optimal_trees(distances, auc_scores)\n",
    "\n",
    "    # Step 6: Select optimal stable tree\n",
    "    best_tree_idx = select_final_tree(distances, auc_scores, pareto_indices)\n",
    "\n",
    "    stable_tree = trees_full_batch[best_tree_idx]\n",
    "\n",
    "    return stable_tree, distances[best_tree_idx], auc_scores[best_tree_idx]\n",
    "\n",
    "\n",
    "# Example usage (User to replace X, y, X_holdout, y_holdout with actual data)\n",
    "# stable_tree, stability_score, auc_score = train_stable_tree(X, y, X_holdout, y_holdout)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
