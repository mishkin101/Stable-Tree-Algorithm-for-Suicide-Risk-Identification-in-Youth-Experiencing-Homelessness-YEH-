{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2563649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = Path(\"../src/dt-distance\").resolve()\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    \n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score# Analy## Visu# d\n",
    "from sklearn.utils import resample\n",
    "from dt_distance.data_processor import DataProcessor  # correct!\n",
    "from dt_distance.tree_parser import TreeParser\n",
    "from dt_distance.distance_calculator import DistanceCalculator\n",
    "from dt_distance.problem_params import ProblemParams\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaff1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params from paper\n",
    "depths = list(range(3, 13))\n",
    "min_samples = [3, 5, 10, 30, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a92e8d",
   "metadata": {},
   "source": [
    "## Step 1: Split Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fcbf26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split data into two batches\n",
    "'''\n",
    "randonly split training data\n",
    "'''\n",
    "def random_train_split(X,y):\n",
    "    N = X.shape[0]\n",
    "    indices = np.random.permutation(N)\n",
    "    return X[indices[:N // 2]], y[indices[:N // 2]]\n",
    "    return X0, y0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceef0ec",
   "metadata": {},
   "source": [
    "## Step 2: Training the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b4b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper function to generate trained tree with sklearn DecisionTreeClassifier\n",
    "'''\n",
    "def train_decision_tree(X, y, depth, min_samples_leaf):\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, min_samples_leaf=min_samples_leaf)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e7c2c5",
   "metadata": {},
   "source": [
    "## Step 3: Bootstrap and Train $T_{0}$ Tree Set\n",
    "- subset $N_0$ of $N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ff82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Takes in X_0\n",
    "Take in full training data\n",
    "Sample with replacement\n",
    "'''\n",
    "def bootstrap_trees(X, y, depths, min_samples, B):\n",
    "    trees = []\n",
    "    for _ in range(B):\n",
    "        X_sample, y_sample = resample(X, y, replace= True)\n",
    "        depth = np.random.choice(depths)\n",
    "        min_leaf = np.random.choice(min_samples)\n",
    "        tree = train_decision_tree(X_sample, y_sample, depth, min_leaf)\n",
    "        trees.append(tree)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2436d",
   "metadata": {},
   "source": [
    "## Step 4: Train Second Tree Collection: $\\mathcal{T}$ (Call Bootstrap trees on X)\n",
    "- full training data $N$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375691cb",
   "metadata": {},
   "source": [
    "## Step 5.1: Compute Mean distance for each $T \\in T$\n",
    "- For each tree in $\\mathcal{T}$, compute `dt-distance` for all $T \\in T_{0}$ and average over all B\n",
    "- Compute AUC score from Test Data to get out-of-sample predictive power\n",
    "- Return $B$ average distances \n",
    "- Intuition for larger set: Say we get new data in the future-> how much do these new trees (entire set)$\\mathcal{T}$ deviate from the previosuly smaller set of trees $T_{0}$?\n",
    "- only structural differences (via path definitions) matter for problem params, so the path_converstion does not care about the dataset, but the bounds on features, quantification of categories, and assigned class labels as a sequence of splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abfd8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_centroid_trees(trees_ref, trees_target, X,y):\n",
    "    X_train_values = X_train.values if hasattr(X_train, 'values') else X_train\n",
    "    \n",
    "    distances = []\n",
    "    for i, tree_b in enumerate(trees_ref):\n",
    "        d_b = 0.0\n",
    "        for tree_beta in trees_target:\n",
    "            print(\"got here\")\n",
    "            distance_calculator = DistanceCalculator(tree_beta, tree_b, X=X_train_values, y=y_train)\n",
    "            d_b += distance_calculator.compute_tree_distance()\n",
    "        d_b /= len(T0)\n",
    "        distances.append(d_b)\n",
    "    \n",
    "    return distances\n",
    "    # X_train_values = X_train.values if hasattr(X_train, 'values') else X_train\n",
    "\n",
    "    # distances = []\n",
    "    # for target_tree in trees_target:\n",
    "    #     d_b = 0.0\n",
    "    #     for ref_tree in trees_ref:\n",
    "    #         distance_calculator = DistanceCalculator(trees_target, ref_tree tree_b,X=X_train_values, y=y_train)\n",
    "    #         d_b += distance_calculator.compute_tree_distance()\n",
    "    #     d_b /= len(T0)\n",
    "    #     distances.append(d_b)\n",
    "    # return distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4241b",
   "metadata": {},
   "source": [
    "## Step 5.2: Compute out-of-sample Predicitive Performance \n",
    "- ROC_AUC score on test-set (our validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6bf6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictive_power(trees, X_holdout, y_holdout):\n",
    "    auc_scores = []\n",
    "    for tree in trees:\n",
    "        y_proba = tree.predict_proba(X_holdout)[:, 1]\n",
    "        auc = roc_auc_score(y_holdout, y_proba)\n",
    "        auc_scores.append(auc)\n",
    "    return auc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115082e9",
   "metadata": {},
   "source": [
    "## Step 6: Find the Pareto Optimal Set $\\mathcal{T}^{*}$ from $\\mathcal{T}$\n",
    "- multi-objective function to find pareto optimal tree set from $\\mathcal{T}$ based on average distance, $d_{b}$ , $\\forall b \\in \\mathcal{T}$ and the out-of-sample AUC_ROC score $a_{b}$, $\\forall b \\in \\mathcal{T}$\n",
    "- **Pareto Optimal Definition:** $(d_{b'} \\leq d_b \\text{ and } \\alpha_{b'} > \\alpha_b) \\text{ or } (d_{b'} < d_b \\text{ and } \\alpha_{b'} \\geq \\alpha_b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282a1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pareto_optimal_trees(distances, auc_scores):\n",
    "    pareto_trees = []\n",
    "    for i, (d_i, a_i) in enumerate(zip(distances, auc_scores)):\n",
    "        dominated = False\n",
    "        for j, (d_j, a_j) in enumerate(zip(distances, auc_scores)):\n",
    "            if i != j and ((d_j <= d_i and a_j > a_i) or (d_j < d_i and a_j >= a_i)):\n",
    "                dominated = True\n",
    "                break\n",
    "        if not dominated:\n",
    "            pareto_trees.append(i)\n",
    "    return pareto_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956476e4",
   "metadata": {},
   "source": [
    "## Step 7: Find the Optimal Tree from the Pareto Optimal Set,  $\\mathcal{T^{*}}$\n",
    "-  $\\mathbb{T}^\\star = \\underset{\\mathbb{T}_b \\in \\mathcal{T}^\\star}{\\text{argmax}} \\ f(d_b, \\alpha_b)$\n",
    "- need to consider here what we value: stability or predicitve power.\n",
    "-  current function is most stable model among all “good enough” performers.\n",
    "- Can modify to find optimal trade-off for accuracy-stability\n",
    "- Indicator function where:\n",
    "    - 1 if $\\alpha_{b}$ is within ε of the best score\n",
    "    - 0 otherwise\n",
    "\n",
    "### Optional Later step: Impose interpretability constraints\n",
    "- increases dimensionality of the multi-objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe2e84e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_final_tree(distances, auc_scores, pareto_indices, epsilon=0.01):\n",
    "    best_auc = max(auc_scores)\n",
    "    candidates = [i for i in pareto_indices if auc_scores[i] >= (1 - epsilon) * best_auc]\n",
    "    if not candidates:\n",
    "        candidates = pareto_indices\n",
    "    best_idx = max(candidates, key=lambda i: auc_scores[i] - distances[i])\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6724bab",
   "metadata": {},
   "source": [
    "### Step 7 Variation Benchmark: AUC maximizing Pareto Critera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "565d7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_auc_tree(auc_scores):\n",
    "    best_idx = np.argmax(auc_scores)\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c5f8a",
   "metadata": {},
   "source": [
    "### Step 7 Variation Benchmark: Distance minimizing Criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "535a22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_distance_tree(distances):\n",
    "    best_idx = np.argmin(distances)\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93744d16",
   "metadata": {},
   "source": [
    "# Main Stable Tree Trainer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8006249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Main method implementing the training of stable trees\n",
    "'''Pareto Objective will return the full_tree_set, pareto_tree_indices, distances, auc_scores'''\n",
    "def generate_pareto_set(X, y, X_holdout, y_holdout, B=20):\n",
    "    # Parameters\n",
    "    depths = list(range(3, 13))\n",
    "    min_samples = [3, 5, 10, 30, 50]\n",
    "\n",
    "    # Step 1: split data\n",
    "    X0, y0 = random_train_split(X.values,y.values)\n",
    "    print(X0.shape)\n",
    "    print(y0.shape)\n",
    "    # Step 2: Train initial collection of trees\n",
    "    trees_batch_0 = bootstrap_trees(X0, y0, depths, min_samples, B)\n",
    "\n",
    "    # Step 3: Train second collection of trees on entire data\n",
    "    trees_full_batch = bootstrap_trees(X, y, depths, min_samples, B)\n",
    "\n",
    "    # Step 4: Compute stability and predictive performance\n",
    "    distances = compute_centroid_trees(trees_batch_0, trees_full_batch, X, y)\n",
    "    auc_scores = evaluate_predictive_power(trees_full_batch, X_holdout.values, y_holdout.values)\n",
    "\n",
    "    '''later save as model class attrbute to visualize'''\n",
    "    # Step 5: Pareto frontier\n",
    "    pareto_indices = pareto_optimal_trees(distances, auc_scores)\n",
    "\n",
    "    return pareto_indices\n",
    "\n",
    "    return trees_full_batch, pareto_indices, distances, scores\n",
    "\n",
    "\n",
    "# Step 6: Select optimal stable tree based o single objective \n",
    "'''Stabler_tree_selector will return the best tree based on the single objective pareto function for the pareto optimal set'''\n",
    "def stable_tree_selector(trees_full_batch, distances, auc_scores, pareto_indices, pareto_obj = None):\n",
    "    if objective == \"balanced\":\n",
    "        best_tree_idx = select_final_tree(distances, auc_scores, pareto_indices)\n",
    "    elif objective == \"auc\":\n",
    "        best_tree_idx = select_best_auc_tree(auc_scores)\n",
    "    elif objective == \"distance\":\n",
    "        best_tree_idx = select_best_distance_tree(distances)\n",
    "\n",
    "    stable_tree = trees_full_batch[best_tree_idx]\n",
    "    return stable_tree, distances[best_tree_idx], auc_scores[best_tree_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bfefcb",
   "metadata": {},
   "source": [
    "# Benchmarking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c5f2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark_models(trees_full_batch, distances, auc_scores, X_holdout, y_holdout):\n",
    "    \"\"\"\n",
    "    Benchmarks the following:\n",
    "    - CART Pareto AUC: Pareto-optimal tree with max AUC\n",
    "    - CART Pareto Distance: Pareto-optimal tree with min distance\n",
    "    - CART CV: Best tree from 5-fold CV\n",
    "    - RF: Random Forest AUC (as baseline)\n",
    "    \"\"\"\n",
    "    pareto_indices = pareto_optimal_trees(distances, auc_scores)\n",
    "\n",
    "    # Best AUC in Pareto\n",
    "    auc_max_idx = max(pareto_indices, key=lambda i: auc_scores[i])\n",
    "    auc_max_tree = trees_full_batch[auc_max_idx]\n",
    "    auc_max_auc = auc_scores[auc_max_idx]\n",
    "\n",
    "    # Best distance in Pareto\n",
    "    dist_min_idx = min(pareto_indices, key=lambda i: distances[i])\n",
    "    dist_min_tree = trees_full_batch[dist_min_idx]\n",
    "    dist_min_auc = auc_scores[dist_min_idx]\n",
    "\n",
    "    # CART CV benchmark (best DT from 5-fold CV)\n",
    "    dt_cv = DecisionTreeClassifier()\n",
    "    cv_probs = cross_val_predict(dt_cv, X_holdout, y_holdout, method='predict_proba',\n",
    "                                 cv=StratifiedKFold(n_splits=5), n_jobs=-1)\n",
    "    cv_auc = roc_auc_score(y_holdout, cv_probs[:, 1])\n",
    "\n",
    "    # Random Forest benchmark\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    rf.fit(X_holdout, y_holdout)\n",
    "    rf_auc = roc_auc_score(y_holdout, rf.predict_proba(X_holdout)[:, 1])\n",
    "\n",
    "    return {\n",
    "        \"CART Pareto AUC\": auc_max_auc,\n",
    "        \"CART Pareto Distance\": dist_min_auc,\n",
    "        \"CART CV\": cv_auc,\n",
    "        \"Random Forest\": rf_auc,\n",
    "        \"models\": {\n",
    "            \"pareto_auc_tree\": auc_max_tree,\n",
    "            \"pareto_dist_tree\": dist_min_tree,\n",
    "            \"random_forest\": rf\n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e6c72b",
   "metadata": {},
   "source": [
    "# Testing Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d512e0",
   "metadata": {},
   "source": [
    "### 1. Generate Full batch of trees on X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bffd9870",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m min_samples = [\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m30\u001b[39m, \u001b[32m50\u001b[39m]  \u001b[38;5;66;03m# min samples per leaf\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Train full batch of trees on entire training set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m trees_full_batch = bootstrap_trees(\u001b[43mX\u001b[49m, y, depths, min_samples, B)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# # Parameters for bootstrap\n",
    "# B = 20  # number of trees\n",
    "# depths = list(range(3, 13))  # depth values from 3 to 12\n",
    "# min_samples = [3, 5, 10, 30, 50]  # min samples per leaf\n",
    "# # Train full batch of trees on entire training set\n",
    "# trees_full_batch = bootstrap_trees(X, y, depths, min_samples, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed702733",
   "metadata": {},
   "source": [
    "# Benchmarking Performance across Pareto-AUC, Pareto-Dist, CVCART, and RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd488e9",
   "metadata": {},
   "source": [
    "### Step 0:  Prepare Suicide Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7496b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded variable 'df' from URI: /Users/mishkin/Desktop/Research/Suicide_Project/data/DataSet_Combined_SI_SNI_Baseline_FE.csv\n",
    "import pandas as pd\n",
    "'''remove other labels we want to predict'''\n",
    "\n",
    "labels = [\"suicidea\", \"suicattempt\", \"suicplan\"]\n",
    "df = pd.read_csv(r'/Users/mishkin/Desktop/Research/Suicide_Project/data/DataSet_Combined_SI_SNI_Baseline_FE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed9be9",
   "metadata": {},
   "source": [
    "### Step 1: Split into train, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "777545a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels to remove except for \"suicidea\"\n",
    "other_labels = [\"suicattempt\", \"suicplan\"]\n",
    "df = df.drop(columns=other_labels, errors='ignore')\n",
    "# Drop rows with missing values in features or label\n",
    "df = df.dropna(subset=[\"suicidea\"])\n",
    "# Split into features and label\n",
    "X = df.drop(columns=[\"suicidea\"])\n",
    "y = df[\"suicidea\"]\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c59d0",
   "metadata": {},
   "source": [
    "### Step 2. Generate Full batch of trees on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4cc9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for bootstrap\n",
    "B = 20  # number of trees\n",
    "depths = list(range(3, 13))  # depth values from 3 to 12\n",
    "min_samples = [3, 5, 10, 30, 50]  # min samples per leaf\n",
    "# Train full batch of trees on entire training set\n",
    "trees_full_batch = bootstrap_trees(X_train.values, y_train.values, depths, min_samples, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26922c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- suic_any <= 0.50\n",
      "|   |--- class: 0.0\n",
      "|--- suic_any >  0.50\n",
      "|   |--- average_alter_known_days <= 1459.42\n",
      "|   |   |--- sum_sex30 <= 0.50\n",
      "|   |   |   |--- class: 1.0\n",
      "|   |   |--- sum_sex30 >  0.50\n",
      "|   |   |   |--- class: 1.0\n",
      "|   |--- average_alter_known_days >  1459.42\n",
      "|   |   |--- class: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_text\n",
    "feature_names = X_train.columns.tolist()\n",
    "tree = trees_full_batch[0]\n",
    "tree_text = export_text(tree, feature_names=feature_names)\n",
    "print(tree_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ed894cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<dt_distance.path_extractor.PathExtractor at 0x1111fd390>,\n",
       " <dt_distance.path_extractor.PathExtractor at 0x13297e790>,\n",
       " <dt_distance.path_extractor.PathExtractor at 0x135cedf90>,\n",
       " <dt_distance.path_extractor.PathExtractor at 0x135cee6d0>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dt_distance.tree_parser import TreeParser\n",
    "from dt_distance.data_processor import DataProcessor\n",
    "dp = DataProcessor(data=X_train.values, target=y_train.values, feature_names=X_train.columns.tolist())\n",
    "problem_params = dp.get_problem_params()\n",
    "\n",
    "parser = TreeParser(tree, problem_params)\n",
    "paths = parser.get_paths()\n",
    "display(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973592e8",
   "metadata": {},
   "source": [
    "### Step 3: Generate Pareto Optimal Set\n",
    "- note passing in X_train, y_train to avoid leakage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "566ae48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 121)\n",
      "(339,)\n",
      "got here\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input for linprog: c must not contain values inf, nan, or None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trees_full_batch, pareto_indices, distances, scores = \u001b[43mgenerate_pareto_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mgenerate_pareto_set\u001b[39m\u001b[34m(X, y, X_holdout, y_holdout, B)\u001b[39m\n\u001b[32m     16\u001b[39m trees_full_batch = bootstrap_trees(X, y, depths, min_samples, B)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Step 4: Compute stability and predictive performance\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m distances = \u001b[43mcompute_centroid_trees\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrees_batch_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrees_full_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m auc_scores = evaluate_predictive_power(trees_full_batch, X_holdout.values, y_holdout.values)\n\u001b[32m     22\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''later save as model class attrbute to visualize'''\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mcompute_centroid_trees\u001b[39m\u001b[34m(trees_ref, trees_target, X, y)\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mgot here\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m     distance_calculator = DistanceCalculator(tree_beta, tree_b, X=X_train_values, y=y_train)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     d_b += \u001b[43mdistance_calculator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_tree_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m d_b /= \u001b[38;5;28mlen\u001b[39m(T0)\n\u001b[32m     12\u001b[39m distances.append(d_b)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/src/dt-distance/dt_distance/distance_calculator.py:174\u001b[39m, in \u001b[36mDistanceCalculator.compute_tree_distance\u001b[39m\u001b[34m(self, print_solver_output)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mself\u001b[39m._compute_paths_distances()\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# Run path matching\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_path_matching\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprint_solver_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_solver_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# Decode solution\u001b[39;00m\n\u001b[32m    176\u001b[39m \u001b[38;5;28mself\u001b[39m._decode_soln()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/src/dt-distance/dt_distance/distance_calculator.py:137\u001b[39m, in \u001b[36mDistanceCalculator._path_matching\u001b[39m\u001b[34m(self, print_solver_output)\u001b[39m\n\u001b[32m    134\u001b[39m A_eq, b_eq, A_inq, b_inq, bounds = \u001b[38;5;28mself\u001b[39m._generate_lp_constraints()\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Solve the LP with both equality and inequality constraints\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m result = \u001b[43mlinprog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_eq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mA_eq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_eq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mb_eq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_ub\u001b[49m\u001b[43m=\u001b[49m\u001b[43mA_inq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_ub\u001b[49m\u001b[43m=\u001b[49m\u001b[43mb_inq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhighs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m                 \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdisp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_solver_output\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result.success:\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLP didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt solve successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/.venv/lib/python3.11/site-packages/scipy/optimize/_linprog.py:649\u001b[39m, in \u001b[36mlinprog\u001b[39m\u001b[34m(c, A_ub, b_ub, A_eq, b_eq, bounds, method, callback, options, x0, integrality)\u001b[39m\n\u001b[32m    646\u001b[39m     integrality = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    648\u001b[39m lp = _LPProblem(c, A_ub, b_ub, A_eq, b_eq, bounds, x0, integrality)\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m lp, solver_options = \u001b[43m_parse_linprog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    650\u001b[39m tol = solver_options.get(\u001b[33m'\u001b[39m\u001b[33mtol\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1e-9\u001b[39m)\n\u001b[32m    652\u001b[39m \u001b[38;5;66;03m# Give unmodified problem to HiGHS\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/.venv/lib/python3.11/site-packages/scipy/optimize/_linprog_util.py:1026\u001b[39m, in \u001b[36m_parse_linprog\u001b[39m\u001b[34m(lp, options, meth)\u001b[39m\n\u001b[32m   1023\u001b[39m solver_options, A_ub, A_eq = _check_sparse_inputs(solver_options, meth,\n\u001b[32m   1024\u001b[39m                                                   lp.A_ub, lp.A_eq)\n\u001b[32m   1025\u001b[39m \u001b[38;5;66;03m# Convert lists to numpy arrays, etc...\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m lp = \u001b[43m_clean_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_replace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_ub\u001b[49m\u001b[43m=\u001b[49m\u001b[43mA_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_eq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mA_eq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lp, solver_options\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/.venv/lib/python3.11/site-packages/scipy/optimize/_linprog_util.py:306\u001b[39m, in \u001b[36m_clean_inputs\u001b[39m\u001b[34m(lp)\u001b[39m\n\u001b[32m    302\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    303\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInvalid input for linprog: c must be a 1-D array and must \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    304\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnot have more than one non-singleton dimension\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(c).all():\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    307\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInvalid input for linprog: c must not contain values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33minf, nan, or None\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    310\u001b[39m sparse_lhs = sps.issparse(A_eq) \u001b[38;5;129;01mor\u001b[39;00m sps.issparse(A_ub)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Invalid input for linprog: c must not contain values inf, nan, or None"
     ]
    }
   ],
   "source": [
    "trees_full_batch, pareto_indices, distances, scores = generate_pareto_set(X_train, y_train, X_holdout, y_holdout, B=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee92cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47a5b51f",
   "metadata": {},
   "source": [
    "### Step 4: Running Stability Performance Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40802769",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = benchmark_models(trees_full_batch, \u001b[43mdistances\u001b[49m, auc_scores, X_holdout, y_holdout)\n",
      "\u001b[31mNameError\u001b[39m: name 'distances' is not defined"
     ]
    }
   ],
   "source": [
    "results = benchmark_models(trees_full_batch, distances, auc_scores, X_holdout, y_holdout)\n",
    "benchmark_results_summary = {k: v for k, v in benchmark_results.items() if k != 'models'}\n",
    "benchmark_results_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
