{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2563649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = Path(\"../src/dt-distance\").resolve()\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score# Analy## Visu# d\n",
    "from sklearn.utils import resample\n",
    "from dt_distance.data_processor import DataProcessor  # correct!\n",
    "from dt_distance.tree_parser import TreeParser\n",
    "from dt_distance.distance_calculator import DistanceCalculator\n",
    "from dt_distance.problem_params import ProblemParams\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaff1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params from paper\n",
    "depths = list(range(3, 13))\n",
    "min_samples = [3, 5, 10, 30, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a92e8d",
   "metadata": {},
   "source": [
    "## Step 1: Split Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fcbf26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split data into two batches\n",
    "'''\n",
    "randonly split training data\n",
    "'''\n",
    "def random_train_split(X,y):\n",
    "    N = X.shape[0]\n",
    "    indices = np.random.permutation(N)\n",
    "    return X.iloc[indices[:N // 2]], y.iloc[indices[:N // 2]]\n",
    "    return X0, y0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceef0ec",
   "metadata": {},
   "source": [
    "## Step 2: Training the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b4b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper function to generate trained tree with sklearn DecisionTreeClassifier\n",
    "'''\n",
    "def train_decision_tree(X, y, depth, min_samples_leaf):\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, min_samples_leaf=min_samples_leaf)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e7c2c5",
   "metadata": {},
   "source": [
    "## Step 3: Bootstrap and Train $T_{0}$ Tree Set\n",
    "- subset $N_0$ of $N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ff82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Takes in X_0\n",
    "Take in full training data\n",
    "Sample with replacement\n",
    "'''\n",
    "def bootstrap_trees(X, y, depths, min_samples, B):\n",
    "    trees = []\n",
    "    for _ in range(B):\n",
    "        X_sample, y_sample = resample(X, y, replace= True)\n",
    "        depth = np.random.choice(depths)\n",
    "        min_leaf = np.random.choice(min_samples)\n",
    "        tree = train_decision_tree(X_sample, y_sample, depth, min_leaf)\n",
    "        trees.append(tree)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2436d",
   "metadata": {},
   "source": [
    "## Step 4: Train Second Tree Collection: $\\mathcal{T}$ (Call Bootstrap trees on X)\n",
    "- full training data $N$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375691cb",
   "metadata": {},
   "source": [
    "## Step 5.1: Compute Mean distance for each $T \\in T$\n",
    "- For each tree in $\\mathcal{T}$, compute `dt-distance` for all $T \\in T_{0}$ and average over all B\n",
    "- Compute AUC score from Test Data to get out-of-sample predictive power\n",
    "- Return $B$ average distances \n",
    "- Intuition for larger set: Say we get new data in the future-> how much do these new trees (entire set)$\\mathcal{T}$ deviate from the previosuly smaller set of trees $T_{0}$?\n",
    "- only structural differences (via path definitions) matter for problem params, so the path_converstion does not care about the dataset, but the bounds on features, quantification of categories, and assigned class labels as a sequence of splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abfd8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_centroid_trees(trees_ref, trees_target, X,y):\n",
    "    distances = []\n",
    "    #TT\n",
    "    for target_tree in trees_target:\n",
    "        #t0\n",
    "        tree_dist_sum = 0\n",
    "        for ref_tree in trees_ref:\n",
    "            distance_calculator = DistanceCalculator(trees_target, ref_tree, X=X, y=y)\n",
    "            tree_dist = distance_calculator.compute_tree_distance()\n",
    "            tree_dist_sum += tree_dist\n",
    "        avg_distance = tree_dist_sum  / len(trees_ref)\n",
    "        distances.append(avg_distance)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4241b",
   "metadata": {},
   "source": [
    "## Step 5.2: Compute out-of-sample Predicitive Performance \n",
    "- ROC_AUC score on test-set (our validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6bf6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictive_power(trees, X_holdout, y_holdout):\n",
    "    auc_scores = []\n",
    "    for tree in trees:\n",
    "        y_proba = tree.predict_proba(X_holdout)[:, 1]\n",
    "        auc = roc_auc_score(y_holdout, y_proba)\n",
    "        auc_scores.append(auc)\n",
    "    return auc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115082e9",
   "metadata": {},
   "source": [
    "## Step 6: Find the Pareto Optimal Set $\\mathcal{T}^{*}$ from $\\mathcal{T}$\n",
    "- multi-objective function to find pareto optimal tree set from $\\mathcal{T}$ based on average distance, $d_{b}$ , $\\forall b \\in \\mathcal{T}$ and the out-of-sample AUC_ROC score $a_{b}$, $\\forall b \\in \\mathcal{T}$\n",
    "- **Pareto Optimal Definition:** $(d_{b'} \\leq d_b \\text{ and } \\alpha_{b'} > \\alpha_b) \\text{ or } (d_{b'} < d_b \\text{ and } \\alpha_{b'} \\geq \\alpha_b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282a1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pareto_optimal_trees(distances, auc_scores):\n",
    "    pareto_trees = []\n",
    "    for i, (d_i, a_i) in enumerate(zip(distances, auc_scores)):\n",
    "        dominated = False\n",
    "        for j, (d_j, a_j) in enumerate(zip(distances, auc_scores)):\n",
    "            if i != j and ((d_j <= d_i and a_j > a_i) or (d_j < d_i and a_j >= a_i)):\n",
    "                dominated = True\n",
    "                break\n",
    "        if not dominated:\n",
    "            pareto_trees.append(i)\n",
    "    return pareto_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956476e4",
   "metadata": {},
   "source": [
    "## Step 7: Find the Optimal Tree from the Pareto Optimal Set,  $\\mathcal{T^{*}}$\n",
    "-  $\\mathbb{T}^\\star = \\underset{\\mathbb{T}_b \\in \\mathcal{T}^\\star}{\\text{argmax}} \\ f(d_b, \\alpha_b)$\n",
    "- need to consider here what we value: stability or predicitve power.\n",
    "-  current function is most stable model among all “good enough” performers.\n",
    "- Can modify to find optimal trade-off for accuracy-stability\n",
    "- Indicator function where:\n",
    "    - 1 if $\\alpha_{b}$ is within ε of the best score\n",
    "    - 0 otherwise\n",
    "\n",
    "### Optional Later step: Impose interpretability constraints\n",
    "- increases dimensionality of the multi-objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe2e84e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_final_tree(distances, auc_scores, pareto_indices, epsilon=0.01):\n",
    "    best_auc = max(auc_scores)\n",
    "    candidates = [i for i in pareto_indices if auc_scores[i] >= (1 - epsilon) * best_auc]\n",
    "    if not candidates:\n",
    "        candidates = pareto_indices\n",
    "    best_idx = max(candidates, key=lambda i: auc_scores[i] - distances[i])\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6724bab",
   "metadata": {},
   "source": [
    "### Step 7 Variation Benchmark: AUC maximizing Pareto Critera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "565d7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_auc_tree(auc_scores):\n",
    "    best_idx = np.argmax(auc_scores)\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c5f8a",
   "metadata": {},
   "source": [
    "### Step 7 Variation Benchmark: Distance minimizing Criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "535a22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_distance_tree(distances):\n",
    "    best_idx = np.argmin(distances)\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93744d16",
   "metadata": {},
   "source": [
    "# Main Stable Tree Trainer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8006249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Main method implementing the training of stable trees\n",
    "'''Pareto Objective will return the full_tree_set, pareto_tree_indices, distances, auc_scores'''\n",
    "def generate_pareto_set(X, y, X_holdout, y_holdout, B=20):\n",
    "    # Parameters\n",
    "    depths = list(range(3, 13))\n",
    "    min_samples = [3, 5, 10, 30, 50]\n",
    "\n",
    "    # Step 1: split data\n",
    "    X0, y0 = random_train_split(X,y)\n",
    "\n",
    "    # Step 2: Train initial collection of trees\n",
    "    trees_batch_0 = bootstrap_trees(X0, y0, depths, min_samples, B)\n",
    "\n",
    "    # Step 3: Train second collection of trees on entire data\n",
    "    trees_full_batch = bootstrap_trees(X, y, depths, min_samples, B)\n",
    "\n",
    "    # Step 4: Compute stability and predictive performance\n",
    "    distances = compute_centroid_trees(trees_batch_0, trees_full_batch, X, y)\n",
    "    auc_scores = evaluate_predictive_power(trees_full_batch, X_holdout, y_holdout)\n",
    "\n",
    "    '''later save as model class attrbute to visualize'''\n",
    "    # Step 5: Pareto frontier\n",
    "    pareto_indices = pareto_optimal_trees(distances, auc_scores)\n",
    "\n",
    "    return pareto_indices\n",
    "\n",
    "    return trees_full_batch, pareto_indices, distances, scores\n",
    "\n",
    "\n",
    "# Step 6: Select optimal stable tree based o single objective \n",
    "'''Stabler_tree_selector will return the best tree based on the single objective pareto function for the pareto optimal set'''\n",
    "def stable_tree_selector(trees_full_batch, distances, auc_scores, pareto_indices, pareto_obj = None):\n",
    "    if objective == \"balanced\":\n",
    "        best_tree_idx = select_final_tree(distances, auc_scores, pareto_indices)\n",
    "    elif objective == \"auc\":\n",
    "        best_tree_idx = select_best_auc_tree(auc_scores)\n",
    "    elif objective == \"distance\":\n",
    "        best_tree_idx = select_best_distance_tree(distances)\n",
    "\n",
    "    stable_tree = trees_full_batch[best_tree_idx]\n",
    "    return stable_tree, distances[best_tree_idx], auc_scores[best_tree_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bfefcb",
   "metadata": {},
   "source": [
    "# Benchmarking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c5f2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark_models(trees_full_batch, distances, auc_scores, X_holdout, y_holdout):\n",
    "    \"\"\"\n",
    "    Benchmarks the following:\n",
    "    - CART Pareto AUC: Pareto-optimal tree with max AUC\n",
    "    - CART Pareto Distance: Pareto-optimal tree with min distance\n",
    "    - CART CV: Best tree from 5-fold CV\n",
    "    - RF: Random Forest AUC (as baseline)\n",
    "    \"\"\"\n",
    "    pareto_indices = pareto_optimal_trees(distances, auc_scores)\n",
    "\n",
    "    # Best AUC in Pareto\n",
    "    auc_max_idx = max(pareto_indices, key=lambda i: auc_scores[i])\n",
    "    auc_max_tree = trees_full_batch[auc_max_idx]\n",
    "    auc_max_auc = auc_scores[auc_max_idx]\n",
    "\n",
    "    # Best distance in Pareto\n",
    "    dist_min_idx = min(pareto_indices, key=lambda i: distances[i])\n",
    "    dist_min_tree = trees_full_batch[dist_min_idx]\n",
    "    dist_min_auc = auc_scores[dist_min_idx]\n",
    "\n",
    "    # CART CV benchmark (best DT from 5-fold CV)\n",
    "    dt_cv = DecisionTreeClassifier()\n",
    "    cv_probs = cross_val_predict(dt_cv, X_holdout, y_holdout, method='predict_proba',\n",
    "                                 cv=StratifiedKFold(n_splits=5), n_jobs=-1)\n",
    "    cv_auc = roc_auc_score(y_holdout, cv_probs[:, 1])\n",
    "\n",
    "    # Random Forest benchmark\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    rf.fit(X_holdout, y_holdout)\n",
    "    rf_auc = roc_auc_score(y_holdout, rf.predict_proba(X_holdout)[:, 1])\n",
    "\n",
    "    return {\n",
    "        \"CART Pareto AUC\": auc_max_auc,\n",
    "        \"CART Pareto Distance\": dist_min_auc,\n",
    "        \"CART CV\": cv_auc,\n",
    "        \"Random Forest\": rf_auc,\n",
    "        \"models\": {\n",
    "            \"pareto_auc_tree\": auc_max_tree,\n",
    "            \"pareto_dist_tree\": dist_min_tree,\n",
    "            \"random_forest\": rf\n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e6c72b",
   "metadata": {},
   "source": [
    "# Testing Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d512e0",
   "metadata": {},
   "source": [
    "### 1. Generate Full batch of trees on X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd9870",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m min_samples = [\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m30\u001b[39m, \u001b[32m50\u001b[39m]  \u001b[38;5;66;03m# min samples per leaf\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Train full batch of trees on entire training set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m trees_full_batch = bootstrap_trees(\u001b[43mX\u001b[49m, y, depths, min_samples, B)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# # Parameters for bootstrap\n",
    "# B = 20  # number of trees\n",
    "# depths = list(range(3, 13))  # depth values from 3 to 12\n",
    "# min_samples = [3, 5, 10, 30, 50]  # min samples per leaf\n",
    "# # Train full batch of trees on entire training set\n",
    "# trees_full_batch = bootstrap_trees(X, y, depths, min_samples, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed702733",
   "metadata": {},
   "source": [
    "# Benchmarking Performance across Pareto-AUC, Pareto-Dist, CVCART, and RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd488e9",
   "metadata": {},
   "source": [
    "### Step 0:  Prepare Suicide Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7496b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded variable 'df' from URI: /Users/mishkin/Desktop/Research/Suicide_Project/data/DataSet_Combined_SI_SNI_Baseline_FE.csv\n",
    "import pandas as pd\n",
    "'''remove other labels we want to predict'''\n",
    "\n",
    "labels = [\"suicidea\", \"suicattempt\", \"suicplan\"]\n",
    "df = pd.read_csv(r'/Users/mishkin/Desktop/Research/Suicide_Project/data/DataSet_Combined_SI_SNI_Baseline_FE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed9be9",
   "metadata": {},
   "source": [
    "### Step 1: Split into train, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "777545a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels to remove except for \"suicidea\"\n",
    "other_labels = [\"suicattempt\", \"suicplan\"]\n",
    "df = df.drop(columns=other_labels, errors='ignore')\n",
    "# Drop rows with missing values in features or label\n",
    "df = df.dropna(subset=[\"suicidea\"])\n",
    "# Split into features and label\n",
    "X = df.drop(columns=[\"suicidea\"])\n",
    "y = df[\"suicidea\"]\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c59d0",
   "metadata": {},
   "source": [
    "### Step 2. Generate Full batch of trees on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for bootstrap\n",
    "B = 20  # number of trees\n",
    "depths = list(range(3, 13))  # depth values from 3 to 12\n",
    "min_samples = [3, 5, 10, 30, 50]  # min samples per leaf\n",
    "# Train full batch of trees on entire training set\n",
    "trees_full_batch = bootstrap_trees(X_train, y_train, depths, min_samples, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26922c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- suic_any <= 0.50\n",
      "|   |--- class: 0.0\n",
      "|--- suic_any >  0.50\n",
      "|   |--- prop_friends_emosup <= 0.58\n",
      "|   |   |--- class: 1.0\n",
      "|   |--- prop_friends_emosup >  0.58\n",
      "|   |   |--- class: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_text\n",
    "feature_names = X_train.columns.tolist()\n",
    "tree = trees_full_batch[0]\n",
    "tree_text = export_text(tree, feature_names=feature_names)\n",
    "print(tree_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973592e8",
   "metadata": {},
   "source": [
    "### Step 3: Generate Pareto Optimal Set\n",
    "- note passing in X_train, y_train to avoid leakage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "566ae48f",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:173\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mInvalidIndexError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trees_full_batch, pareto_indices, distances, scores = \u001b[43mgenerate_pareto_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mgenerate_pareto_set\u001b[39m\u001b[34m(X, y, X_holdout, y_holdout, B)\u001b[39m\n\u001b[32m     15\u001b[39m trees_full_batch = bootstrap_trees(X, y, depths, min_samples, B)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Step 4: Compute stability and predictive performance\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m distances = \u001b[43mcompute_centroid_trees\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrees_batch_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrees_full_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m auc_scores = evaluate_predictive_power(trees_full_batch, X_holdout, y_holdout)\n\u001b[32m     21\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''later save as model class attrbute to visualize'''\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mcompute_centroid_trees\u001b[39m\u001b[34m(trees_ref, trees_target, X, y)\u001b[39m\n\u001b[32m      6\u001b[39m tree_dist_sum = \u001b[32m0\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ref_tree \u001b[38;5;129;01min\u001b[39;00m trees_ref:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     distance_calculator = \u001b[43mDistanceCalculator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrees_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     tree_dist = distance_calculator.compute_tree_distance()\n\u001b[32m     10\u001b[39m     tree_dist_sum += tree_dist\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/src/dt-distance/dt_distance/distance_calculator.py:38\u001b[39m, in \u001b[36mDistanceCalculator.__init__\u001b[39m\u001b[34m(self, tree1, tree2, problem_params, X, y, dataset_name, max_depth, normalize_distance, outcome_weight_in_path, round_digits)\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mself\u001b[39m.problem_params = problem_params\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     data_processor = \u001b[43mDataProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28mself\u001b[39m.problem_params = data_processor.get_problem_params()\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Check if input is list of paths or sklearn tree models\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/src/dt-distance/dt_distance/data_processor.py:36\u001b[39m, in \u001b[36mDataProcessor.__init__\u001b[39m\u001b[34m(self, data, target, feature_names, feature_types, dataset_name)\u001b[39m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mself\u001b[39m._load_predefined_dataset()\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_custom_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/src/dt-distance/dt_distance/data_processor.py:67\u001b[39m, in \u001b[36mDataProcessor._process_custom_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Automatically determine feature types if not provided\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_types:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28mself\u001b[39m.feature_types = \u001b[43m{\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetermine_feature_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m._setup_problem_params()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/src/dt-distance/dt_distance/data_processor.py:67\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Automatically determine feature types if not provided\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_types:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28mself\u001b[39m.feature_types = {i: determine_feature_type(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.data.shape[\u001b[32m1\u001b[39m])}\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m._setup_problem_params()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3817\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3817\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3818\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/Suicide_Project/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6059\u001b[39m, in \u001b[36mIndex._check_indexing_error\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   6055\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   6056\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[32m   6057\u001b[39m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[32m   6058\u001b[39m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6059\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[31mInvalidIndexError\u001b[39m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "trees_full_batch, pareto_indices, distances, scores = generate_pareto_set(X_train, y_train, X_holdout, y_holdout, B=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5b51f",
   "metadata": {},
   "source": [
    "### Step 4: Running Stability Performance Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40802769",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = benchmark_models(trees_full_batch, \u001b[43mdistances\u001b[49m, auc_scores, X_holdout, y_holdout)\n",
      "\u001b[31mNameError\u001b[39m: name 'distances' is not defined"
     ]
    }
   ],
   "source": [
    "results = benchmark_models(trees_full_batch, distances, auc_scores, X_holdout, y_holdout)\n",
    "benchmark_results_summary = {k: v for k, v in benchmark_results.items() if k != 'models'}\n",
    "benchmark_results_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
